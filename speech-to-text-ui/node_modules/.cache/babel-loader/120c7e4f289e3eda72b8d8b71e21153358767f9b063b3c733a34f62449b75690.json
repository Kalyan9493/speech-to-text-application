{"ast":null,"code":"var _jsxFileName = \"C:\\\\desktop\\\\Personal Projects\\\\speech-to-text\\\\src\\\\SpeechToText.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SpeechToText = () => {\n  _s();\n  const [text, setText] = useState([]);\n  const [isListening, setIsListening] = useState(false);\n  const [recognition, setRecognition] = useState(null);\n  const [lastTimestamp, setLastTimestamp] = useState(Date.now());\n  useEffect(() => {\n    // Initialize the SpeechRecognition instance when the component mounts\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (SpeechRecognition) {\n      const recog = new SpeechRecognition();\n      recog.continuous = true;\n      recog.interimResults = true;\n      recog.lang = 'en-IN'; // Set to English (India)\n\n      recog.onresult = event => {\n        const currentTime = Date.now();\n        let transcript = '';\n        for (let i = 0; i < event.results.length; i++) {\n          transcript += event.results[i][0].transcript;\n        }\n\n        // Check if there is a gap of more than 1 second between speech segments\n        if (currentTime - lastTimestamp > 1000) {\n          setText(prevText => [...prevText, transcript]); // Add a new line with the current transcript\n        } else {\n          setText(prevText => {\n            const updatedText = [...prevText];\n            updatedText[updatedText.length - 1] += ' ' + transcript; // Append to the last line\n            return updatedText;\n          });\n        }\n        setLastTimestamp(currentTime); // Update the timestamp\n      };\n      recog.onerror = event => {\n        console.error(\"Speech recognition error:\", event.error);\n        setIsListening(false);\n      };\n      recog.onend = () => {\n        // Restart recognition if it's stopped unintentionally (e.g., by a timeout)\n        if (isListening) {\n          recog.start();\n        }\n      };\n      setRecognition(recog);\n    } else {\n      alert(\"Your browser does not support speech recognition.\");\n    }\n  }, [isListening, lastTimestamp]);\n  const handleClick = () => {\n    if (isListening) {\n      recognition.stop();\n      setIsListening(false);\n    } else {\n      recognition.start();\n      setIsListening(true);\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: handleClick,\n      children: isListening ? 'Stop Listening' : 'Start Listening'\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 70,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: text.map((line, index) => /*#__PURE__*/_jsxDEV(\"p\", {\n        children: line\n      }, index, false, {\n        fileName: _jsxFileName,\n        lineNumber: 75,\n        columnNumber: 11\n      }, this))\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 73,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 69,\n    columnNumber: 5\n  }, this);\n};\n_s(SpeechToText, \"La/pK++p9tRzM+wTHh4PT8S4H5M=\");\n_c = SpeechToText;\nexport default SpeechToText;\nvar _c;\n$RefreshReg$(_c, \"SpeechToText\");","map":{"version":3,"names":["React","useState","useEffect","jsxDEV","_jsxDEV","SpeechToText","_s","text","setText","isListening","setIsListening","recognition","setRecognition","lastTimestamp","setLastTimestamp","Date","now","SpeechRecognition","window","webkitSpeechRecognition","recog","continuous","interimResults","lang","onresult","event","currentTime","transcript","i","results","length","prevText","updatedText","onerror","console","error","onend","start","alert","handleClick","stop","children","onClick","fileName","_jsxFileName","lineNumber","columnNumber","map","line","index","_c","$RefreshReg$"],"sources":["C:/desktop/Personal Projects/speech-to-text/src/SpeechToText.js"],"sourcesContent":["import React, { useState, useEffect } from 'react';\r\n\r\nconst SpeechToText = () => {\r\n  const [text, setText] = useState([]);\r\n  const [isListening, setIsListening] = useState(false);\r\n  const [recognition, setRecognition] = useState(null);\r\n  const [lastTimestamp, setLastTimestamp] = useState(Date.now());\r\n\r\n  useEffect(() => {\r\n    // Initialize the SpeechRecognition instance when the component mounts\r\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n    if (SpeechRecognition) {\r\n      const recog = new SpeechRecognition();\r\n      recog.continuous = true;\r\n      recog.interimResults = true;\r\n      recog.lang = 'en-IN'; // Set to English (India)\r\n\r\n      recog.onresult = (event) => {\r\n        const currentTime = Date.now();\r\n\r\n        let transcript = '';\r\n        for (let i = 0; i < event.results.length; i++) {\r\n          transcript += event.results[i][0].transcript;\r\n        }\r\n\r\n        // Check if there is a gap of more than 1 second between speech segments\r\n        if (currentTime - lastTimestamp > 1000) {\r\n          setText(prevText => [...prevText, transcript]); // Add a new line with the current transcript\r\n        } else {\r\n          setText(prevText => {\r\n            const updatedText = [...prevText];\r\n            updatedText[updatedText.length - 1] += ' ' + transcript; // Append to the last line\r\n            return updatedText;\r\n          });\r\n        }\r\n\r\n        setLastTimestamp(currentTime); // Update the timestamp\r\n      };\r\n\r\n      recog.onerror = (event) => {\r\n        console.error(\"Speech recognition error:\", event.error);\r\n        setIsListening(false);\r\n      };\r\n\r\n      recog.onend = () => {\r\n        // Restart recognition if it's stopped unintentionally (e.g., by a timeout)\r\n        if (isListening) {\r\n          recog.start();\r\n        }\r\n      };\r\n\r\n      setRecognition(recog);\r\n    } else {\r\n      alert(\"Your browser does not support speech recognition.\");\r\n    }\r\n  }, [isListening, lastTimestamp]);\r\n\r\n  const handleClick = () => {\r\n    if (isListening) {\r\n      recognition.stop();\r\n      setIsListening(false);\r\n    } else {\r\n      recognition.start();\r\n      setIsListening(true);\r\n    }\r\n  };\r\n\r\n  return (\r\n    <div>\r\n      <button onClick={handleClick}>\r\n        {isListening ? 'Stop Listening' : 'Start Listening'}\r\n      </button>\r\n      <div>\r\n        {text.map((line, index) => (\r\n          <p key={index}>{line}</p>\r\n        ))}\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default SpeechToText;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEnD,MAAMC,YAAY,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACzB,MAAM,CAACC,IAAI,EAAEC,OAAO,CAAC,GAAGP,QAAQ,CAAC,EAAE,CAAC;EACpC,MAAM,CAACQ,WAAW,EAAEC,cAAc,CAAC,GAAGT,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,IAAI,CAAC;EACpD,MAAM,CAACY,aAAa,EAAEC,gBAAgB,CAAC,GAAGb,QAAQ,CAACc,IAAI,CAACC,GAAG,CAAC,CAAC,CAAC;EAE9Dd,SAAS,CAAC,MAAM;IACd;IACA,MAAMe,iBAAiB,GAAGC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;IACpF,IAAIF,iBAAiB,EAAE;MACrB,MAAMG,KAAK,GAAG,IAAIH,iBAAiB,CAAC,CAAC;MACrCG,KAAK,CAACC,UAAU,GAAG,IAAI;MACvBD,KAAK,CAACE,cAAc,GAAG,IAAI;MAC3BF,KAAK,CAACG,IAAI,GAAG,OAAO,CAAC,CAAC;;MAEtBH,KAAK,CAACI,QAAQ,GAAIC,KAAK,IAAK;QAC1B,MAAMC,WAAW,GAAGX,IAAI,CAACC,GAAG,CAAC,CAAC;QAE9B,IAAIW,UAAU,GAAG,EAAE;QACnB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGH,KAAK,CAACI,OAAO,CAACC,MAAM,EAAEF,CAAC,EAAE,EAAE;UAC7CD,UAAU,IAAIF,KAAK,CAACI,OAAO,CAACD,CAAC,CAAC,CAAC,CAAC,CAAC,CAACD,UAAU;QAC9C;;QAEA;QACA,IAAID,WAAW,GAAGb,aAAa,GAAG,IAAI,EAAE;UACtCL,OAAO,CAACuB,QAAQ,IAAI,CAAC,GAAGA,QAAQ,EAAEJ,UAAU,CAAC,CAAC,CAAC,CAAC;QAClD,CAAC,MAAM;UACLnB,OAAO,CAACuB,QAAQ,IAAI;YAClB,MAAMC,WAAW,GAAG,CAAC,GAAGD,QAAQ,CAAC;YACjCC,WAAW,CAACA,WAAW,CAACF,MAAM,GAAG,CAAC,CAAC,IAAI,GAAG,GAAGH,UAAU,CAAC,CAAC;YACzD,OAAOK,WAAW;UACpB,CAAC,CAAC;QACJ;QAEAlB,gBAAgB,CAACY,WAAW,CAAC,CAAC,CAAC;MACjC,CAAC;MAEDN,KAAK,CAACa,OAAO,GAAIR,KAAK,IAAK;QACzBS,OAAO,CAACC,KAAK,CAAC,2BAA2B,EAAEV,KAAK,CAACU,KAAK,CAAC;QACvDzB,cAAc,CAAC,KAAK,CAAC;MACvB,CAAC;MAEDU,KAAK,CAACgB,KAAK,GAAG,MAAM;QAClB;QACA,IAAI3B,WAAW,EAAE;UACfW,KAAK,CAACiB,KAAK,CAAC,CAAC;QACf;MACF,CAAC;MAEDzB,cAAc,CAACQ,KAAK,CAAC;IACvB,CAAC,MAAM;MACLkB,KAAK,CAAC,mDAAmD,CAAC;IAC5D;EACF,CAAC,EAAE,CAAC7B,WAAW,EAAEI,aAAa,CAAC,CAAC;EAEhC,MAAM0B,WAAW,GAAGA,CAAA,KAAM;IACxB,IAAI9B,WAAW,EAAE;MACfE,WAAW,CAAC6B,IAAI,CAAC,CAAC;MAClB9B,cAAc,CAAC,KAAK,CAAC;IACvB,CAAC,MAAM;MACLC,WAAW,CAAC0B,KAAK,CAAC,CAAC;MACnB3B,cAAc,CAAC,IAAI,CAAC;IACtB;EACF,CAAC;EAED,oBACEN,OAAA;IAAAqC,QAAA,gBACErC,OAAA;MAAQsC,OAAO,EAAEH,WAAY;MAAAE,QAAA,EAC1BhC,WAAW,GAAG,gBAAgB,GAAG;IAAiB;MAAAkC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7C,CAAC,eACT1C,OAAA;MAAAqC,QAAA,EACGlC,IAAI,CAACwC,GAAG,CAAC,CAACC,IAAI,EAAEC,KAAK,kBACpB7C,OAAA;QAAAqC,QAAA,EAAgBO;MAAI,GAAZC,KAAK;QAAAN,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAW,CACzB;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACC,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAACxC,EAAA,CA7EID,YAAY;AAAA6C,EAAA,GAAZ7C,YAAY;AA+ElB,eAAeA,YAAY;AAAC,IAAA6C,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}