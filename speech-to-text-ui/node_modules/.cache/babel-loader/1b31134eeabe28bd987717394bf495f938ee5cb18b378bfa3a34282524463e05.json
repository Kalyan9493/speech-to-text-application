{"ast":null,"code":"var _jsxFileName = \"C:\\\\desktop\\\\Personal Projects\\\\speech-to-text\\\\src\\\\SpeechToText.js\",\n  _s = $RefreshSig$();\n// import React, { useState, useEffect, useRef } from 'react';\n\n// const SpeechToText = () => {\n//   const [text, setText] = useState([]); // Store transcribed text segments\n//   const [isListening, setIsListening] = useState(false); // Toggle listening state\n//   const recognitionRef = useRef(null); // Ref to store SpeechRecognition instance\n//   const [interimTranscript, setInterimTranscript] = useState(''); // Store interim results\n\n//   useEffect(() => {\n//     // Initialize the SpeechRecognition instance\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n//     if (SpeechRecognition) {\n//       const recog = new SpeechRecognition();\n//       recog.continuous = true;\n//       recog.interimResults = true; // Enable interim results for real-time transcription\n//       recog.lang = 'en-IN'; // Set to English (India)\n\n//       recog.onresult = (event) => {\n//         let finalTranscript = '';\n//         let interimTranscript = '';\n\n//         for (let i = event.resultIndex; i < event.results.length; i++) {\n//           const transcript = event.results[i][0].transcript.trim();\n//           if (event.results[i].isFinal) {\n//             finalTranscript += transcript + ' ';\n//           } else {\n//             interimTranscript += transcript + ' ';\n//           }\n//         }\n\n//         setInterimTranscript(interimTranscript); // Update interim transcript\n\n//         if (finalTranscript) {\n//           setText(prevText => [...prevText, finalTranscript]); // Add final results to text\n//           setInterimTranscript(''); // Clear interim results once they are finalized\n//         }\n//       };\n\n//       recog.onerror = (event) => {\n//         console.error('Speech recognition error:', event.error);\n//         setIsListening(false);\n//       };\n\n//       recog.onend = () => {\n//         if (isListening) {\n//           recog.start(); // Restart recognition if still listening\n//         }\n//       };\n\n//       recognitionRef.current = recog; // Store the recognition instance in ref\n//     } else {\n//       alert('Your browser does not support speech recognition.');\n//     }\n//   }, [isListening]);\n\n//   const startListening = () => {\n//     if (recognitionRef.current) {\n//       recognitionRef.current.start();\n//       setIsListening(true);\n//     }\n//   };\n\n//   const stopListening = () => {\n//     if (recognitionRef.current) {\n//       recognitionRef.current.stop();\n//       setIsListening(false);\n//     }\n//   };\n\n//   return (\n//     <div>\n//       <button onClick={isListening ? stopListening : startListening}>\n//         {isListening ? 'Stop Listening' : 'Start Listening'}\n//       </button>\n//       <div>\n//         {text.map((line, index) => (\n//           <p key={index}>{line}</p>\n//         ))}\n//         {interimTranscript && <p style={{ color: 'gray' }}>{interimTranscript}</p>}\n//       </div>\n//     </div>\n//   );\n// };\n\n// export default SpeechToText;\n\nimport React, { useState, useEffect, useRef } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SpeechToText = ({\n  sessionId\n}) => {\n  _s();\n  const [text, setText] = useState([]); // Store transcribed text segments\n  const [isListening, setIsListening] = useState(false); // Toggle listening state\n  const recognitionRef = useRef(null); // Ref to store SpeechRecognition instance\n  const socketRef = useRef(null); // Ref to store WebSocket instance\n  const [interimTranscript, setInterimTranscript] = useState(''); // Store interim results\n\n  useEffect(() => {\n    // Connect to WebSocket server\n    socketRef.current = new WebSocket(`ws://localhost:5000?session=${sessionId}`);\n    socketRef.current.onmessage = event => {\n      const receivedText = JSON.parse(event.data);\n      setText(prevText => [...prevText, receivedText]);\n    };\n    return () => {\n      socketRef.current.close(); // Cleanup on unmount\n    };\n  }, [sessionId]);\n  useEffect(() => {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (SpeechRecognition) {\n      const recog = new SpeechRecognition();\n      recog.continuous = true;\n      recog.interimResults = true; // Enable interim results for real-time transcription\n      recog.lang = 'en-IN'; // Set to English (India)\n\n      recog.onresult = event => {\n        let finalTranscript = '';\n        let interimTranscript = '';\n        for (let i = event.resultIndex; i < event.results.length; i++) {\n          const transcript = event.results[i][0].transcript.trim();\n          if (event.results[i].isFinal) {\n            finalTranscript += transcript + ' ';\n          } else {\n            interimTranscript += transcript + ' ';\n          }\n        }\n        setInterimTranscript(interimTranscript); // Update interim transcript\n\n        if (finalTranscript) {\n          setText(prevText => [...prevText, finalTranscript]); // Add final results to text\n          setInterimTranscript(''); // Clear interim results once they are finalized\n\n          // Transmit the final transcript to the WebSocket server\n          socketRef.current.send(JSON.stringify(finalTranscript));\n        }\n      };\n      recog.onerror = event => {\n        console.error('Speech recognition error:', event.error);\n        setIsListening(false);\n      };\n      recog.onend = () => {\n        if (isListening) {\n          recog.start(); // Restart recognition if still listening\n        }\n      };\n      recognitionRef.current = recog; // Store the recognition instance in ref\n    } else {\n      alert('Your browser does not support speech recognition.');\n    }\n  }, [isListening]);\n  const startListening = () => {\n    if (recognitionRef.current) {\n      recognitionRef.current.start();\n      setIsListening(true);\n    }\n  };\n  const stopListening = () => {\n    if (recognitionRef.current) {\n      recognitionRef.current.stop();\n      setIsListening(false);\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: isListening ? stopListening : startListening,\n      children: isListening ? 'Stop Listening' : 'Start Listening'\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 180,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [text.map((line, index) => /*#__PURE__*/_jsxDEV(\"p\", {\n        children: line\n      }, index, false, {\n        fileName: _jsxFileName,\n        lineNumber: 185,\n        columnNumber: 11\n      }, this)), interimTranscript && /*#__PURE__*/_jsxDEV(\"p\", {\n        style: {\n          color: 'gray'\n        },\n        children: interimTranscript\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 187,\n        columnNumber: 31\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 183,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 179,\n    columnNumber: 5\n  }, this);\n};\n_s(SpeechToText, \"cgHETMUJq9aF/s1L7tW04V+rgeU=\");\n_c = SpeechToText;\nexport default SpeechToText;\nvar _c;\n$RefreshReg$(_c, \"SpeechToText\");","map":{"version":3,"names":["React","useState","useEffect","useRef","jsxDEV","_jsxDEV","SpeechToText","sessionId","_s","text","setText","isListening","setIsListening","recognitionRef","socketRef","interimTranscript","setInterimTranscript","current","WebSocket","onmessage","event","receivedText","JSON","parse","data","prevText","close","SpeechRecognition","window","webkitSpeechRecognition","recog","continuous","interimResults","lang","onresult","finalTranscript","i","resultIndex","results","length","transcript","trim","isFinal","send","stringify","onerror","console","error","onend","start","alert","startListening","stopListening","stop","children","onClick","fileName","_jsxFileName","lineNumber","columnNumber","map","line","index","style","color","_c","$RefreshReg$"],"sources":["C:/desktop/Personal Projects/speech-to-text/src/SpeechToText.js"],"sourcesContent":["// import React, { useState, useEffect, useRef } from 'react';\r\n\r\n// const SpeechToText = () => {\r\n//   const [text, setText] = useState([]); // Store transcribed text segments\r\n//   const [isListening, setIsListening] = useState(false); // Toggle listening state\r\n//   const recognitionRef = useRef(null); // Ref to store SpeechRecognition instance\r\n//   const [interimTranscript, setInterimTranscript] = useState(''); // Store interim results\r\n\r\n//   useEffect(() => {\r\n//     // Initialize the SpeechRecognition instance\r\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n//     if (SpeechRecognition) {\r\n//       const recog = new SpeechRecognition();\r\n//       recog.continuous = true;\r\n//       recog.interimResults = true; // Enable interim results for real-time transcription\r\n//       recog.lang = 'en-IN'; // Set to English (India)\r\n\r\n//       recog.onresult = (event) => {\r\n//         let finalTranscript = '';\r\n//         let interimTranscript = '';\r\n\r\n//         for (let i = event.resultIndex; i < event.results.length; i++) {\r\n//           const transcript = event.results[i][0].transcript.trim();\r\n//           if (event.results[i].isFinal) {\r\n//             finalTranscript += transcript + ' ';\r\n//           } else {\r\n//             interimTranscript += transcript + ' ';\r\n//           }\r\n//         }\r\n\r\n//         setInterimTranscript(interimTranscript); // Update interim transcript\r\n\r\n//         if (finalTranscript) {\r\n//           setText(prevText => [...prevText, finalTranscript]); // Add final results to text\r\n//           setInterimTranscript(''); // Clear interim results once they are finalized\r\n//         }\r\n//       };\r\n\r\n//       recog.onerror = (event) => {\r\n//         console.error('Speech recognition error:', event.error);\r\n//         setIsListening(false);\r\n//       };\r\n\r\n//       recog.onend = () => {\r\n//         if (isListening) {\r\n//           recog.start(); // Restart recognition if still listening\r\n//         }\r\n//       };\r\n\r\n//       recognitionRef.current = recog; // Store the recognition instance in ref\r\n//     } else {\r\n//       alert('Your browser does not support speech recognition.');\r\n//     }\r\n//   }, [isListening]);\r\n\r\n//   const startListening = () => {\r\n//     if (recognitionRef.current) {\r\n//       recognitionRef.current.start();\r\n//       setIsListening(true);\r\n//     }\r\n//   };\r\n\r\n//   const stopListening = () => {\r\n//     if (recognitionRef.current) {\r\n//       recognitionRef.current.stop();\r\n//       setIsListening(false);\r\n//     }\r\n//   };\r\n\r\n//   return (\r\n//     <div>\r\n//       <button onClick={isListening ? stopListening : startListening}>\r\n//         {isListening ? 'Stop Listening' : 'Start Listening'}\r\n//       </button>\r\n//       <div>\r\n//         {text.map((line, index) => (\r\n//           <p key={index}>{line}</p>\r\n//         ))}\r\n//         {interimTranscript && <p style={{ color: 'gray' }}>{interimTranscript}</p>}\r\n//       </div>\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default SpeechToText;\r\n\r\n\r\n\r\n\r\n\r\n\r\nimport React, { useState, useEffect, useRef } from 'react';\r\n\r\nconst SpeechToText = ({ sessionId }) => {\r\n  const [text, setText] = useState([]); // Store transcribed text segments\r\n  const [isListening, setIsListening] = useState(false); // Toggle listening state\r\n  const recognitionRef = useRef(null); // Ref to store SpeechRecognition instance\r\n  const socketRef = useRef(null); // Ref to store WebSocket instance\r\n  const [interimTranscript, setInterimTranscript] = useState(''); // Store interim results\r\n\r\n  useEffect(() => {\r\n    // Connect to WebSocket server\r\n    socketRef.current = new WebSocket(`ws://localhost:5000?session=${sessionId}`);\r\n\r\n    socketRef.current.onmessage = (event) => {\r\n      const receivedText = JSON.parse(event.data);\r\n      setText(prevText => [...prevText, receivedText]);\r\n    };\r\n\r\n    return () => {\r\n      socketRef.current.close(); // Cleanup on unmount\r\n    };\r\n  }, [sessionId]);\r\n\r\n  useEffect(() => {\r\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n    if (SpeechRecognition) {\r\n      const recog = new SpeechRecognition();\r\n      recog.continuous = true;\r\n      recog.interimResults = true; // Enable interim results for real-time transcription\r\n      recog.lang = 'en-IN'; // Set to English (India)\r\n\r\n      recog.onresult = (event) => {\r\n        let finalTranscript = '';\r\n        let interimTranscript = '';\r\n\r\n        for (let i = event.resultIndex; i < event.results.length; i++) {\r\n          const transcript = event.results[i][0].transcript.trim();\r\n          if (event.results[i].isFinal) {\r\n            finalTranscript += transcript + ' ';\r\n          } else {\r\n            interimTranscript += transcript + ' ';\r\n          }\r\n        }\r\n\r\n        setInterimTranscript(interimTranscript); // Update interim transcript\r\n\r\n        if (finalTranscript) {\r\n          setText(prevText => [...prevText, finalTranscript]); // Add final results to text\r\n          setInterimTranscript(''); // Clear interim results once they are finalized\r\n\r\n          // Transmit the final transcript to the WebSocket server\r\n          socketRef.current.send(JSON.stringify(finalTranscript));\r\n        }\r\n      };\r\n\r\n      recog.onerror = (event) => {\r\n        console.error('Speech recognition error:', event.error);\r\n        setIsListening(false);\r\n      };\r\n\r\n      recog.onend = () => {\r\n        if (isListening) {\r\n          recog.start(); // Restart recognition if still listening\r\n        }\r\n      };\r\n\r\n      recognitionRef.current = recog; // Store the recognition instance in ref\r\n    } else {\r\n      alert('Your browser does not support speech recognition.');\r\n    }\r\n  }, [isListening]);\r\n\r\n  const startListening = () => {\r\n    if (recognitionRef.current) {\r\n      recognitionRef.current.start();\r\n      setIsListening(true);\r\n    }\r\n  };\r\n\r\n  const stopListening = () => {\r\n    if (recognitionRef.current) {\r\n      recognitionRef.current.stop();\r\n      setIsListening(false);\r\n    }\r\n  };\r\n\r\n  return (\r\n    <div>\r\n      <button onClick={isListening ? stopListening : startListening}>\r\n        {isListening ? 'Stop Listening' : 'Start Listening'}\r\n      </button>\r\n      <div>\r\n        {text.map((line, index) => (\r\n          <p key={index}>{line}</p>\r\n        ))}\r\n        {interimTranscript && <p style={{ color: 'gray' }}>{interimTranscript}</p>}\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default SpeechToText;\r\n"],"mappings":";;AAAA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAOA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE3D,MAAMC,YAAY,GAAGA,CAAC;EAAEC;AAAU,CAAC,KAAK;EAAAC,EAAA;EACtC,MAAM,CAACC,IAAI,EAAEC,OAAO,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC,CAAC,CAAC;EACtC,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;EACvD,MAAMY,cAAc,GAAGV,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;EACrC,MAAMW,SAAS,GAAGX,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;EAChC,MAAM,CAACY,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGf,QAAQ,CAAC,EAAE,CAAC,CAAC,CAAC;;EAEhEC,SAAS,CAAC,MAAM;IACd;IACAY,SAAS,CAACG,OAAO,GAAG,IAAIC,SAAS,CAAC,+BAA+BX,SAAS,EAAE,CAAC;IAE7EO,SAAS,CAACG,OAAO,CAACE,SAAS,GAAIC,KAAK,IAAK;MACvC,MAAMC,YAAY,GAAGC,IAAI,CAACC,KAAK,CAACH,KAAK,CAACI,IAAI,CAAC;MAC3Cd,OAAO,CAACe,QAAQ,IAAI,CAAC,GAAGA,QAAQ,EAAEJ,YAAY,CAAC,CAAC;IAClD,CAAC;IAED,OAAO,MAAM;MACXP,SAAS,CAACG,OAAO,CAACS,KAAK,CAAC,CAAC,CAAC,CAAC;IAC7B,CAAC;EACH,CAAC,EAAE,CAACnB,SAAS,CAAC,CAAC;EAEfL,SAAS,CAAC,MAAM;IACd,MAAMyB,iBAAiB,GAAGC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;IACpF,IAAIF,iBAAiB,EAAE;MACrB,MAAMG,KAAK,GAAG,IAAIH,iBAAiB,CAAC,CAAC;MACrCG,KAAK,CAACC,UAAU,GAAG,IAAI;MACvBD,KAAK,CAACE,cAAc,GAAG,IAAI,CAAC,CAAC;MAC7BF,KAAK,CAACG,IAAI,GAAG,OAAO,CAAC,CAAC;;MAEtBH,KAAK,CAACI,QAAQ,GAAId,KAAK,IAAK;QAC1B,IAAIe,eAAe,GAAG,EAAE;QACxB,IAAIpB,iBAAiB,GAAG,EAAE;QAE1B,KAAK,IAAIqB,CAAC,GAAGhB,KAAK,CAACiB,WAAW,EAAED,CAAC,GAAGhB,KAAK,CAACkB,OAAO,CAACC,MAAM,EAAEH,CAAC,EAAE,EAAE;UAC7D,MAAMI,UAAU,GAAGpB,KAAK,CAACkB,OAAO,CAACF,CAAC,CAAC,CAAC,CAAC,CAAC,CAACI,UAAU,CAACC,IAAI,CAAC,CAAC;UACxD,IAAIrB,KAAK,CAACkB,OAAO,CAACF,CAAC,CAAC,CAACM,OAAO,EAAE;YAC5BP,eAAe,IAAIK,UAAU,GAAG,GAAG;UACrC,CAAC,MAAM;YACLzB,iBAAiB,IAAIyB,UAAU,GAAG,GAAG;UACvC;QACF;QAEAxB,oBAAoB,CAACD,iBAAiB,CAAC,CAAC,CAAC;;QAEzC,IAAIoB,eAAe,EAAE;UACnBzB,OAAO,CAACe,QAAQ,IAAI,CAAC,GAAGA,QAAQ,EAAEU,eAAe,CAAC,CAAC,CAAC,CAAC;UACrDnB,oBAAoB,CAAC,EAAE,CAAC,CAAC,CAAC;;UAE1B;UACAF,SAAS,CAACG,OAAO,CAAC0B,IAAI,CAACrB,IAAI,CAACsB,SAAS,CAACT,eAAe,CAAC,CAAC;QACzD;MACF,CAAC;MAEDL,KAAK,CAACe,OAAO,GAAIzB,KAAK,IAAK;QACzB0B,OAAO,CAACC,KAAK,CAAC,2BAA2B,EAAE3B,KAAK,CAAC2B,KAAK,CAAC;QACvDnC,cAAc,CAAC,KAAK,CAAC;MACvB,CAAC;MAEDkB,KAAK,CAACkB,KAAK,GAAG,MAAM;QAClB,IAAIrC,WAAW,EAAE;UACfmB,KAAK,CAACmB,KAAK,CAAC,CAAC,CAAC,CAAC;QACjB;MACF,CAAC;MAEDpC,cAAc,CAACI,OAAO,GAAGa,KAAK,CAAC,CAAC;IAClC,CAAC,MAAM;MACLoB,KAAK,CAAC,mDAAmD,CAAC;IAC5D;EACF,CAAC,EAAE,CAACvC,WAAW,CAAC,CAAC;EAEjB,MAAMwC,cAAc,GAAGA,CAAA,KAAM;IAC3B,IAAItC,cAAc,CAACI,OAAO,EAAE;MAC1BJ,cAAc,CAACI,OAAO,CAACgC,KAAK,CAAC,CAAC;MAC9BrC,cAAc,CAAC,IAAI,CAAC;IACtB;EACF,CAAC;EAED,MAAMwC,aAAa,GAAGA,CAAA,KAAM;IAC1B,IAAIvC,cAAc,CAACI,OAAO,EAAE;MAC1BJ,cAAc,CAACI,OAAO,CAACoC,IAAI,CAAC,CAAC;MAC7BzC,cAAc,CAAC,KAAK,CAAC;IACvB;EACF,CAAC;EAED,oBACEP,OAAA;IAAAiD,QAAA,gBACEjD,OAAA;MAAQkD,OAAO,EAAE5C,WAAW,GAAGyC,aAAa,GAAGD,cAAe;MAAAG,QAAA,EAC3D3C,WAAW,GAAG,gBAAgB,GAAG;IAAiB;MAAA6C,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7C,CAAC,eACTtD,OAAA;MAAAiD,QAAA,GACG7C,IAAI,CAACmD,GAAG,CAAC,CAACC,IAAI,EAAEC,KAAK,kBACpBzD,OAAA;QAAAiD,QAAA,EAAgBO;MAAI,GAAZC,KAAK;QAAAN,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAW,CACzB,CAAC,EACD5C,iBAAiB,iBAAIV,OAAA;QAAG0D,KAAK,EAAE;UAAEC,KAAK,EAAE;QAAO,CAAE;QAAAV,QAAA,EAAEvC;MAAiB;QAAAyC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACvE,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAACnD,EAAA,CAjGIF,YAAY;AAAA2D,EAAA,GAAZ3D,YAAY;AAmGlB,eAAeA,YAAY;AAAC,IAAA2D,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}